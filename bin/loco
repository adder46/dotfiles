#!/usr/bin/env python3

import re
import subprocess
from pathlib import Path
from typing import Dict

HEADERS = ('Files', 'Lines', 'Code', 'Comments', 'Blanks')
REGEX = r'Total\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)'


def parse_tokei_output(output: str) -> Dict[str, str]:
    data = re.search(REGEX, output).groups()
    return dict(zip(HEADERS, data))


def write_markdown(projects: Dict[str, str]) -> None:
    wordiest_project = max(projects.keys(), key=len)
    minimum_length = len(wordiest_project)
    headers = ['Project'.ljust(minimum_length)]
    headers += [header.ljust(10) for header in HEADERS]
    header_lengths = [len(header) for header in headers]
    separators = ['-' * len(header) for header in headers]

    with open('loco_result.md', 'w') as f:
        print('|' + '|'.join(headers) + '|', file=f)
        print('|' + '|'.join(separators) + '|', file=f)
        for project, stats in sorted(projects.items()):
            print(f'|{project.ljust(minimum_length)}|', end='', file=f)
            print(
                '|'.join(
                    stats.ljust(header_length)
                    for header_length, stats in zip(header_lengths[1:], stats.values())
                ),
                end='|\n',
                file=f,
            )


def main() -> None:
    projects = {}

    for project in Path('.').iterdir():
        if project.is_dir():
            stats = subprocess.check_output(['tokei', project])
            stats = stats.decode('utf-8')
            projects[project.name] = parse_tokei_output(stats)

    write_markdown(projects)


if __name__ == '__main__':
    main()